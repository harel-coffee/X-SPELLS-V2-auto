{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Picking counterfactuals\n",
    "\n",
    "Alternative implementations of diversity optimization for picking counterfactuals by function q instead of g\n",
    "\n",
    "Evaluation, generation function and n_covers algorithm only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" naive max cover \"\"\"\n",
    "def ncover(aset, f=None, k=None, df=None, verbose=False):\n",
    "    if k is None or k >= len(aset):\n",
    "        k = len(aset)\n",
    "    pset = list(aset)\n",
    "    # covers is accumulated greedy set\n",
    "    covers = []\n",
    "    for i in range(k):\n",
    "        if df is None: # optimize f\n",
    "            bestp, value = argmax(pset, lambda x: f(covers + [x]) )\n",
    "        else: # optimize df\n",
    "            bestp, value = argmax(pset, lambda x: df(covers, x) )\n",
    "            if value <= 0:\n",
    "                break\n",
    "        covers.append(pset[bestp])\n",
    "        if verbose:\n",
    "            if df is None:\n",
    "                print('it:', i, 'x:', pset[bestp], 'f:', value)\n",
    "            else:\n",
    "                print('it:', i, 'x:', pset[bestp], 'f:', df(covers), 'df:', value)\n",
    "        del pset[bestp]\n",
    "    return covers\n",
    "\n",
    "def EVAL_find_counter_exemplars(latent_representation_original, Z, idxs, counter_exemplar_idxs):\n",
    "    \"\"\"\n",
    "    Compute the values of the goal function.\n",
    "    \n",
    "    Change goal function to q (or f)\n",
    "    \n",
    "    \"\"\"\n",
    "    # prepare the data to apply the diversity optimization \n",
    "    data = np.zeros((len(idxs), np.shape(Z)[1]))\n",
    "    for i in range(len(idxs)):\n",
    "        data[i] = Z[idxs[i]]            \n",
    "        \n",
    "    # min-max normalization (applied on ALL examples)\n",
    "    scaler = MinMaxScaler()\n",
    "    scaler.fit_transform(data)\n",
    "    \n",
    "    # list of points\n",
    "    points = [row for row in scaler.transform(data)]\n",
    "    # MIN MAX normalize instance to explain\n",
    "    instance = scaler.transform((latent_representation_original))\n",
    "    \n",
    "    lconst = 1.5\n",
    "    \n",
    "    #### original definition of optimizing function\n",
    "    def f(points):\n",
    "        n = len(points)\n",
    "        if n==0:\n",
    "            return 0\n",
    "        dpoints = dx = 0\n",
    "        for i, p1 in enumerate(points):\n",
    "            dx += dist(p1, instance)\n",
    "            for p2 in points[i+1:]:\n",
    "                dpoints += dist(p1, p2)\n",
    "        dpoints /= (n*n)/2\n",
    "        dx /= n\n",
    "        return dpoints - lconst * dx\n",
    "\n",
    "    \n",
    "    # get the extracted CF\n",
    "    extracted_CF_data = []\n",
    "    for i in range(len(counter_exemplar_idxs)):\n",
    "        extracted_CF_data.append(Z[counter_exemplar_idxs[i]]) \n",
    "        \n",
    "    # apply scaling\n",
    "    extracted_CF_data = scaler.transform((extracted_CF_data))\n",
    "    \n",
    "    return f(extracted_CF_data)\n",
    "\n",
    "        \n",
    "\n",
    "def DIVERSITY_find_counter_exemplars(latent_representation_original, Z, idxs, metric, count):\n",
    "    \"\"\"\n",
    "    Pick CF based on diversity optimization.\n",
    "    Additionally, the consecutive values of the goal function is returned\n",
    "    \n",
    "    Change this function: from g to q (or f)\n",
    "    \"\"\"\n",
    "        \n",
    "    # prepare the data to apply the diversity optimization \n",
    "    data = np.zeros((len(idxs), np.shape(Z)[1]))\n",
    "    for i in range(len(idxs)):\n",
    "        data[i] = Z[idxs[i]]            \n",
    "        \n",
    "    # min-max normalization (applied on ALL examples)\n",
    "    scaler = MinMaxScaler()\n",
    "    scaler.fit_transform(data)\n",
    "    \n",
    "    # list of points\n",
    "    points = [row for row in scaler.transform(data)]\n",
    "    # MIN MAX normalize instance to explain\n",
    "    instance = scaler.transform((latent_representation_original))\n",
    "    \n",
    "    lconst = 1.5\n",
    "            \n",
    "    #### original definition of optimizing function\n",
    "    def f(points):\n",
    "        n = len(points)\n",
    "        if n==0:\n",
    "            return 0\n",
    "        dpoints = dx = 0\n",
    "        for i, p1 in enumerate(points):\n",
    "            dx += dist(p1, instance)\n",
    "            for p2 in points[i+1:]:\n",
    "                dpoints += dist(p1, p2)\n",
    "        dpoints /= (n*n)/2\n",
    "        dx /= n\n",
    "        return dpoints - lconst * dx\n",
    "\n",
    "    # Greedy algorithms\n",
    "    #from acover import ncover, acover, argmax\n",
    "\n",
    "    # cannot use acover since f is ...\n",
    "    covers = ncover(points, f, k=5, verbose=False)\n",
    "    # from list back to matrix\n",
    "    cov = np.concatenate([ [a] for a in covers])\n",
    "    # and rescale to original coordinates\n",
    "    cov = scaler.inverse_transform( cov )\n",
    "    \n",
    "    # get back the indices of the elements that are chosen by the greedy algorithm\n",
    "    \n",
    "    data_indices = []\n",
    "    \n",
    "    for i in range(len(cov)):\n",
    "        for j in range(len(data)):\n",
    "            if np.allclose(cov[i], data[j]):\n",
    "                data_indices.append(j)\n",
    "            \n",
    "    # convert into CF indices so that we can return a list that holds only CF elements, generated by greedy alg\n",
    "    \n",
    "    final_indices = []\n",
    "    \n",
    "    for i in range(len(data_indices)):\n",
    "        final_indices.append(idxs[data_indices[i]])\n",
    "        \n",
    "    # get back the original data\n",
    "    # print(Z[final_indices[i]])\n",
    "\n",
    "    return final_indices"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda env_3 clone",
   "language": "python",
   "name": "clone_xspells_conda_env_3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
