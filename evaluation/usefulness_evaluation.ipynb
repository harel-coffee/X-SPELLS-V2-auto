{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Usefulness evaluation\n",
    "\n",
    "Same script for distance/diversity and BVAE/OVAE (BVAE here)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Usefulness Evaluation\n",
    "\n",
    "Uses knn to first predict the class of the given instance using the synthetic exemplars and counter exemplars\n",
    "and secondly using real sentences from the train set of the respective dataset.\n",
    "\"\"\"\n",
    "\n",
    "import pickle\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import vectorize\n",
    "from pre_processing import get_text_data, YOUTUBE_get_text_data\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to use knn on synthetic exemplars and counter exemplars\n",
    "def knn_predict_on_synthetic_sentences(instance, number_exemplars, prediction, exemplars_holder,\n",
    "                                       counter_exemplars_holder):\n",
    "    knn_X_train = list()\n",
    "    knn_y_train = list()\n",
    "    for t in range(len(exemplars_holder + counter_exemplars_holder)):\n",
    "        knn_X_train = exemplars_holder + counter_exemplars_holder\n",
    "        if prediction == 0:\n",
    "            knn_y_train = [0 for _ in range(number_exemplars)] + [1 for _ in range(number_exemplars)]\n",
    "        else:\n",
    "            knn_y_train = [1 for _ in range(number_exemplars)] + [0 for _ in range(number_exemplars)]\n",
    "            \n",
    "    knn_X_train, knn_X_test = vectorize.createTFIDF(knn_X_train, instance, remove_stopwords=True, lemmatize=True,\n",
    "                                                    stemmer=False)\n",
    "\n",
    "    knn = sklearn.neighbors.KNeighborsClassifier(n_neighbors=1, weights='distance', algorithm='brute', leaf_size=30,\n",
    "                                                 p=2, metric='cosine', metric_params=None, n_jobs=-1)\n",
    "\n",
    "    knn.fit(knn_X_train, knn_y_train)\n",
    "    prediction = knn.predict(knn_X_test)\n",
    "    return prediction[0]\n",
    "\n",
    "\n",
    "# Function to use knn with real sentences as training data\n",
    "def knn_predict_on_real_sentences(instance, number_exemplars, sentences, classes):\n",
    "    np_classes = np.array(classes)\n",
    "    neutral_sentence_list = list()\n",
    "    hate_sentence_list = list()\n",
    "    neutral_prediction_list = list()\n",
    "    hate_prediction_list = list()\n",
    "\n",
    "    neutral_class_idx = np.where(np_classes == 0)[0]\n",
    "    hate_class_idx = np.where(np_classes == 1)[0]\n",
    "\n",
    "    for t in neutral_class_idx:\n",
    "        neutral_sentence_list.append(sentences[t])\n",
    "        neutral_prediction_list.append(classes[t])\n",
    "\n",
    "    for t in hate_class_idx:\n",
    "        hate_sentence_list.append(sentences[t])\n",
    "        hate_prediction_list.append(classes[t])\n",
    "\n",
    "    neutral_dict = list(zip(neutral_sentence_list, neutral_prediction_list))  # make pairs out of the two lists\n",
    "    neutral_pairs = random.sample(neutral_dict, number_exemplars)  # pick k random pairs\n",
    "    X_neutral, y_neutral = zip(*neutral_pairs)  # separate the pairs\n",
    "\n",
    "    hate_dict = list(zip(hate_sentence_list, hate_prediction_list))  # make pairs out of the two lists\n",
    "    hate_pairs = random.sample(hate_dict, number_exemplars)  # pick k random pairs\n",
    "    X_hate, y_hate = zip(*hate_pairs)  # separate the pairs\n",
    "\n",
    "    X_train = X_neutral + X_hate\n",
    "    y_train = y_neutral + y_hate\n",
    "\n",
    "    X_train, X_test = vectorize.createTFIDF(X_train, instance, remove_stopwords=True, lemmatize=True, stemmer=False)\n",
    "    knn = sklearn.neighbors.KNeighborsClassifier(n_neighbors=1, weights='distance', algorithm='brute', leaf_size=30,\n",
    "                                                 p=2, metric='cosine', metric_params=None, n_jobs=-1)\n",
    "\n",
    "    knn.fit(X_train, y_train)\n",
    "    prediction = knn.predict(X_test)\n",
    "    return prediction[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Set dataset, model and maximum nbr of exemplars\n",
    "\n",
    "datasets = [\"hate\", \"polarity\", \"youtube\"]\n",
    "models = [\"RF\", \"DNN\"]\n",
    "max_nbr_exemplars = 5  # Should not be longer than the max exemplars used for training x-spells\n",
    "\n",
    "#vaes = [\"BVAE\", \"OVAE\"]\n",
    "\n",
    "for i, dataset in enumerate(datasets):\n",
    "    for j2, model in enumerate(models):\n",
    "        \n",
    "        results_synthetic_c = []\n",
    "        results_real_c = []\n",
    "        \n",
    "        for k, vae in enumerate(vaes):\n",
    "        \n",
    "            results_synthetic = []\n",
    "            results_real = []\n",
    "\n",
    "            # Load saved exemplars and counter-exemplars for demonstration\n",
    "            if dataset == \"hate\":\n",
    "                with open(DATAPATH + dataset + '_' + model + '_' + 'exemplars', 'rb') as f:\n",
    "                    loaded_exemplars = pickle.load(f)\n",
    "\n",
    "                with open(DATAPATH + dataset + '_' + model + '_' + 'counter_exemplars', 'rb') as f:\n",
    "                    loaded_counter_exemplars = pickle.load(f)\n",
    "\n",
    "            elif dataset == \"polarity\":\n",
    "                with open(DATAPATH + dataset + '_' + model + '_' + 'exemplars', 'rb') as f:\n",
    "                    loaded_exemplars = pickle.load(f)\n",
    "\n",
    "                with open(DATAPATH + dataset + '_' + model + '_' + 'counter_exemplars', 'rb') as f:\n",
    "                    loaded_counter_exemplars = pickle.load(f)\n",
    "\n",
    "            elif dataset == \"youtube\":\n",
    "                with open(DATAPATH + dataset + '_' + model + '_' + 'exemplars', 'rb') as f:\n",
    "                    loaded_exemplars = pickle.load(f)\n",
    "\n",
    "                with open(DATAPATH + dataset + '_' + model + '_' + 'counter_exemplars', 'rb') as f:\n",
    "                    loaded_counter_exemplars = pickle.load(f)\n",
    "            \n",
    "            # dataset loading\n",
    "            if dataset == \"youtube\":\n",
    "                _, _, y_train, y_test, X_train, X_test = YOUTUBE_get_text_data('data/YouTube-Spam-Collection-v1/' + dataset + '.csv', dataset)\n",
    "            else:\n",
    "                _, _, y_train, y_test, X_train, X_test = get_text_data('data/' + dataset + '_tweets.csv', dataset)\n",
    "\n",
    "            #print(np.shape(loaded_counter_exemplars))\n",
    "\n",
    "            # Iterate from 1 to 5 exemplars, inclusive\n",
    "            for no_exemplars in range(1, max_nbr_exemplars + 1):\n",
    "                knnpreds = list()\n",
    "                knn_real_sentences_preds = list()\n",
    "                true_classes = list()\n",
    "\n",
    "                for j in range(len(loaded_exemplars)):\n",
    "                    true_classes.append(y_test[j])\n",
    "                    exemplars = loaded_exemplars[j][:no_exemplars]\n",
    "                    counter_exemplars = loaded_counter_exemplars[j][:no_exemplars]\n",
    "\n",
    "                    # Train the knn classifier by using synthetic sentences i.e. the exemplars and counter exemplars\n",
    "                    knn_synthetic_prediction = knn_predict_on_synthetic_sentences(X_test[j], no_exemplars, y_test[j], exemplars,\n",
    "                                                                                  counter_exemplars)\n",
    "                    # Train the knn classifier by using real sentences from the train set\n",
    "                    knn_real_sentences_prediction = knn_predict_on_real_sentences(X_test[j], no_exemplars, X_train, y_train)\n",
    "\n",
    "                    knnpreds.append(knn_synthetic_prediction)\n",
    "                    knn_real_sentences_preds.append(knn_real_sentences_prediction)\n",
    "\n",
    "                knn_synthetic_vs_true_fidelity = accuracy_score(knnpreds, true_classes)\n",
    "                knn_real_vs_true_fidelity = accuracy_score(knn_real_sentences_preds, true_classes)\n",
    "\n",
    "                results_synthetic.append(knn_synthetic_vs_true_fidelity)\n",
    "                results_real.append(knn_real_vs_true_fidelity)\n",
    "                \n",
    "            results_synthetic_c.append(results_synthetic)\n",
    "            results_real_c.append(results_real)\n",
    "\n",
    "        fontsize = 20\n",
    "        plt.figure(figsize=(5, 3))\n",
    "      \n",
    "        plt.xlabel('no. of (counter-)exemplars', fontsize=fontsize)\n",
    "\n",
    "        plt.plot(range(5), results_synthetic_c[0], linestyle=\"-\", color = \"tab:blue\", marker = \"o\", label='BVAE')\n",
    "        plt.plot(range(5), results_synthetic_c[1], linestyle=\"-\", color = \"orange\",marker = \"o\", label='OVAE')\n",
    "        plt.plot(range(5), np.mean(results_real_c, axis = 0), linestyle=\"-\", color = \"grey\", marker = \"o\", label='baseline')\n",
    "\n",
    "        plt.title('%s %s' % (dataset, model), fontsize=fontsize)\n",
    "\n",
    "        plt.ylabel('accuracy', fontsize=fontsize)\n",
    "        plt.yticks(np.arange(0.0, 1.05, 0.2))\n",
    "        plt.grid(axis='y')\n",
    "        plt.tick_params(axis='both', which='major', labelsize=16)\n",
    "                  \n",
    "        plt.tight_layout()    \n",
    "        #plt.savefig(model + '_' + dataset + '_.pdf', bbox_inches='tight')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda env_3 clone",
   "language": "python",
   "name": "clone_xspells_conda_env_3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
