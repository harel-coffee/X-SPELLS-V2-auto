{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "anchor3",
      "language": "python",
      "name": "anchor3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.7"
    },
    "colab": {
      "name": "Anchor for text.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lstate/X-SPELLS-V2/blob/main/experiments/anchor_text.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LsiVplnxV4SZ"
      },
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "import os\n",
        "import os.path\n",
        "import re\n",
        "import string\n",
        "\n",
        "import numpy as np\n",
        "import sklearn\n",
        "import sklearn.model_selection\n",
        "import sklearn.linear_model\n",
        "import sklearn.ensemble\n",
        "import spacy\n",
        "import sys\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "!pip install anchor_exp\n",
        "from anchor import anchor_text\n",
        "import time"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H6pq1JZFV4Sd"
      },
      "source": [
        "def cleanText(var):\n",
        "    # replace punctuation with spaces\n",
        "    var = re.sub('[{}]'.format(string.punctuation), \" \", var)\n",
        "    # remove double spaces\n",
        "    var = re.sub(r'\\s+', \" \", var)\n",
        "    # put in lower case\n",
        "    var = var.lower().split()\n",
        "    # remove words that are smaller than 3 characters\n",
        "    var = [w for w in var if len(w) >= 3]\n",
        "    var = \" \".join(var)\n",
        "    return var\n",
        "\n",
        "# Removes 'rt' from all input data\n",
        "def my_clean(text):\n",
        "    text = text.lower().split()\n",
        "    text = [w for w in text]\n",
        "    text = \" \".join(text)\n",
        "    text = re.sub(r\"rt\", \"\", text)\n",
        "    return text\n",
        "\n",
        "# Removes 'rt' from all input data\n",
        "# Removes emojis from all input data\n",
        "def YOUTUBE_my_clean(text):\n",
        "    text = text.lower().split()\n",
        "    text = [w for w in text]\n",
        "    text = \" \".join(text)\n",
        "    text = re.sub(r\"rt\", \"\", text)\n",
        "    emoji_pattern = re.compile(\"[\"\n",
        "                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
        "                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
        "                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
        "                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
        "                           u\"\\U00002702-\\U000027B0\"\n",
        "                           u\"\\U000024C2-\\U0001F251\"\n",
        "                           \"]+\", flags=re.UNICODE)\n",
        "    text = re.sub(emoji_pattern, '', text)\n",
        "    return text\n",
        "\n",
        "\n",
        "def strip_links(text):\n",
        "    link_regex = re.compile('((https?):((//)|(\\\\\\\\))+([\\w\\d:#@%/;$()~_?\\+-=\\\\\\.&](#!)?)*)', re.DOTALL)\n",
        "    links = re.findall(link_regex, text)\n",
        "    for link in links:\n",
        "        text = text.replace(link[0], ', ')\n",
        "    return text\n",
        "\n",
        "\n",
        "def strip_all_entities(text):\n",
        "    entity_prefixes = ['@', '#']\n",
        "    for separator in string.punctuation:\n",
        "        if separator not in entity_prefixes:\n",
        "            text = text.replace(separator, ' ')\n",
        "    words = []\n",
        "    for word in text.split():\n",
        "        word = word.strip()\n",
        "        if word:\n",
        "            if word[0] not in entity_prefixes:\n",
        "                words.append(word)\n",
        "    return ' '.join(words)\n",
        "\n",
        "\n",
        "def preProcessing(strings):\n",
        "    clean_tweet_texts = []\n",
        "    for string in strings:\n",
        "        clean_tweet_texts.append(my_clean(strip_all_entities(strip_links(string))))\n",
        "        # clean_tweet_texts.append(my_clean(string))\n",
        "    return clean_tweet_texts\n",
        "\n",
        "def YOUTUBE_preProcessing(strings):\n",
        "    clean_tweet_texts = []\n",
        "    for string in strings:\n",
        "        clean_tweet_texts.append(YOUTUBE_my_clean(strip_all_entities(strip_links(string))))\n",
        "        # clean_tweet_texts.append(my_clean(string))\n",
        "    return clean_tweet_texts\n",
        "\n",
        "def load_dataset(dataset):\n",
        "    if dataset == \"polarity\":\n",
        "        df = pd.read_csv('https://raw.githubusercontent.com/lstate/X-SPELLS-V2/main/data/' + dataset_name + '_tweets.csv', encoding='utf-8')\n",
        "        X = df['tweet'].values\n",
        "        y = df['class'].values\n",
        "\n",
        "    elif dataset == \"hate\":\n",
        "        df = pd.read_csv('https://raw.githubusercontent.com/lstate/X-SPELLS-V2/main/data/' + dataset_name + '_tweets.csv', encoding='utf-8')\n",
        "        # Removing the offensive comments, keeping only neutral and hatespeech,\n",
        "        # and convert the class value from 2 to 1 for simplification purposes\n",
        "        df = df[df['class'] != 1]\n",
        "        X = df['tweet'].values\n",
        "        y = df['class'].apply(lambda x: 1 if x == 2 else 0).values\n",
        "\n",
        "    elif dataset == \"liar\":\n",
        "        df_train = pd.read_csv(\"https://raw.githubusercontent.com/lstate/X-SPELLS-V2/main/data/liar_dataset/train.tsv\", encoding='utf-8', sep='\\t')\n",
        "        df_test = pd.read_csv(\"https://raw.githubusercontent.com/lstate/X-SPELLS-V2/main/data/liar_dataset/test.tsv\", encoding='utf-8', sep='\\t')\n",
        "        df_val = pd.read_csv(\"https://raw.githubusercontent.com/lstate/X-SPELLS-V2/main/data/liar_dataset/valid.tsv\", encoding='utf-8', sep='\\t')\n",
        "\n",
        "        mapping = {'pants-fire': 0,\n",
        "                   'false': 0,\n",
        "                   'barely-true': 0,\n",
        "                   'half-true': 1,\n",
        "                   'mostly-true': 1,\n",
        "                   'true': 1}\n",
        "\n",
        "        df_train.iloc[:, 1] = df_train.iloc[:, 1].apply(lambda x: mapping[x])\n",
        "        df_test.iloc[:, 1] = df_test.iloc[:, 1].apply(lambda x: mapping[x])\n",
        "        df_val.iloc[:, 1] = df_val.iloc[:, 1].apply(lambda x: mapping[x])\n",
        "\n",
        "        # Removing middle columns\n",
        "        df_train = df_train[df_train.iloc[:, 1] != 2]\n",
        "        df_test = df_test[df_test.iloc[:, 1] != 2]\n",
        "        df_val = df_val[df_val.iloc[:, 1] != 2]\n",
        "\n",
        "        X_train = df_train.iloc[:, 2].values\n",
        "        y_train = df_train.iloc[:, 1].values\n",
        "        X_test = df_test.iloc[:, 2].values\n",
        "        y_test = df_test.iloc[:, 1].values\n",
        "        X_val = df_val.iloc[:, 2].values\n",
        "        y_val = df_val.iloc[:, 1].values\n",
        "\n",
        "        Xtt = np.append(X_train, X_test)\n",
        "        ytt = np.append(y_train, y_test)\n",
        "        X = np.append(Xtt, X_val)\n",
        "        y = np.append(ytt, y_val)\n",
        "\n",
        "    elif dataset == 'question':\n",
        "        df_train = pd.read_csv((\"https://raw.githubusercontent.com/lstate/X-SPELLS-V2/main/data/question_dataset/question_train.txt\"),\n",
        "                               encoding='ISO-8859-1', sep=':',\n",
        "                               error_bad_lines=False, header=None)\n",
        "        df_test = pd.read_csv((\"https://raw.githubusercontent.com/lstate/X-SPELLS-V2/main/data/question_dataset/question_test.txt\"),\n",
        "                              encoding='ISO-8859-1', sep=':',\n",
        "                              error_bad_lines=False, header=None)\n",
        "\n",
        "        def remove_first_word(string):\n",
        "            return string.partition(' ')[2]\n",
        "\n",
        "        df_train.iloc[:, 1] = df_train.iloc[:, 1].apply(remove_first_word)\n",
        "        df_test.iloc[:, 1] = df_test.iloc[:, 1].apply(remove_first_word)\n",
        "\n",
        "        X_train = df_train.iloc[:, 1].values\n",
        "        y_train = df_train.iloc[:, 0].values\n",
        "        X_test = df_test.iloc[:, 1].values\n",
        "        y_test = df_test.iloc[:, 0].values\n",
        "\n",
        "        X_train = preProcessing(X_train)\n",
        "        X_test = preProcessing(X_test)\n",
        "\n",
        "        X = np.append(X_train, X_test)\n",
        "        y = np.append(y_train, y_test)\n",
        "\n",
        "        # Which class to define as 0 depends on the distribution of data.\n",
        "        # We pick the class with the largest number of instances.\n",
        "        mapping = {'DESC': 1,\n",
        "                   'ENTY': 0,\n",
        "                   'ABBR': 1,\n",
        "                   'HUM': 1,\n",
        "                   'NUM': 1,\n",
        "                   'LOC': 1}\n",
        "\n",
        "        df_train.iloc[:, 0] = df_train.iloc[:, 0].apply(lambda x: mapping[x])\n",
        "        df_test.iloc[:, 0] = df_test.iloc[:, 0].apply(lambda x: mapping[x])\n",
        "\n",
        "        X_train = df_train.iloc[:, 1].values\n",
        "        y_train = df_train.iloc[:, 0].values\n",
        "        X_test = df_test.iloc[:, 1].values\n",
        "        y_test = df_test.iloc[:, 0].values\n",
        "\n",
        "        X = np.append(X_train, X_test)\n",
        "        y = np.append(y_train, y_test)\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, stratify=y, test_size=0.25)\n",
        "\n",
        "    X_test = preProcessing(X_test)\n",
        "\n",
        "    return X_test, y_test\n",
        "\n",
        "def YOUTUBE_get_text_data():\n",
        "    df = pd.read_csv('https://raw.githubusercontent.com/lstate/X-SPELLS-V2/main/data/YouTube-Spam-Collection-v1/youtube.csv', encoding='utf-8')\n",
        "\n",
        "    X = df[\"CONTENT\"].values\n",
        "    y = df[\"CLASS\"].values\n",
        "        \n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, stratify=y, test_size=0.25)\n",
        "    \n",
        "    X_test = YOUTUBE_preProcessing(X_test)\n",
        "    \n",
        "    # delete x/y where there is no more content after preprocessing or we have more than 140 characters (e.g. comment was only an url)\n",
        "    \n",
        "    indx = []\n",
        "    for i in range(len(X_test)):\n",
        "        if len(X_test[i]) == 0:\n",
        "            indx.append(i)\n",
        "        elif len(X_test[i]) > 140:\n",
        "            indx.append(i)     \n",
        "    X_test = np.delete(X_test, indx, 0)\n",
        "    y_test = np.delete(y_test, indx, 0)\n",
        "    \n",
        "    return X_test, y_test"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yaBYnn7bV4Si"
      },
      "source": [
        "!pip install spacy && python -m spacy download en_core_web_sm\n",
        "!pip install torch transformers spacy && python -m spacy download en_core_web_sm\n",
        "\n",
        "nlp = spacy.load('en_core_web_sm')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kNQRMM4L2iCu"
      },
      "source": [
        "# Hate Speech"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2X5KSUWGV4Sj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d2c02033-93f0-4dd0-86f1-5ad8941b85ed"
      },
      "source": [
        "dataset_name = 'hate'\n",
        "data, labels = load_dataset(dataset_name)\n",
        "train, test, train_labels, test_labels = sklearn.model_selection.train_test_split(data, labels, test_size=0.25, random_state=42)\n",
        "train_labels = np.array(train_labels)\n",
        "test_labels = np.array(test_labels)\n",
        "\n",
        "vectorizer = TfidfVectorizer()\n",
        "vectorizer.fit(train)\n",
        "train_vectors = vectorizer.transform(train)\n",
        "test_vectors = vectorizer.transform(test)\n",
        "\n",
        "c = sklearn.ensemble.RandomForestClassifier()\n",
        "c.fit(train_vectors, train_labels)\n",
        "\n",
        "preds = c.predict(test_vectors)\n",
        "\n",
        "print(classification_report(test_labels, preds))\n",
        "print(\"The accuracy score is {:.2%}\".format(accuracy_score(test_labels, preds)))\n",
        "\n",
        "def predict_lr(texts):\n",
        "    return c.predict(vectorizer.transform(texts))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.70      0.79        87\n",
            "           1       0.91      0.98      0.94       263\n",
            "\n",
            "    accuracy                           0.91       350\n",
            "   macro avg       0.91      0.84      0.87       350\n",
            "weighted avg       0.91      0.91      0.90       350\n",
            "\n",
            "The accuracy score is 90.86%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k-UEpRnaV4TK"
      },
      "source": [
        "## Without using BERT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EhYjtRUBV4TP",
        "outputId": "cd952088-4a8b-405c-8b22-006939b4575c"
      },
      "source": [
        "explainer = anchor_text.AnchorText(nlp, ['hate-speech', 'neutral'], use_unk_distribution=True)\n",
        "\n",
        "np.random.seed(1)\n",
        "text = 'fat ass hoe holding up the machine'\n",
        "pred = explainer.class_names[predict_lr([text])[0]]\n",
        "alternative =  explainer.class_names[1 - predict_lr([text])[0]]\n",
        "exp = explainer.explain_instance(text, predict_lr, threshold=0.95)\n",
        "\n",
        "print('Text: %s' % text)\n",
        "print('Prediction: %s' % pred)\n",
        "print()\n",
        "print('Anchor: %s' % (' AND '.join(exp.names())))\n",
        "print('Precision: %.2f' % exp.precision())\n",
        "print()\n",
        "print('Examples where anchor applies and model predicts %s:' % pred)\n",
        "print()\n",
        "print('\\n'.join([x[0] for x in exp.examples(only_same_prediction=True)]))\n",
        "print()\n",
        "print('Examples where anchor applies and model predicts %s:' % alternative)\n",
        "print()\n",
        "print('\\n'.join([x[0] for x in exp.examples(partial_index=0, only_different_prediction=True)]))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text: fat ass hoe holding up the machine\n",
            "Prediction: hate-speech\n",
            "\n",
            "Anchor: ass\n",
            "Precision: 1.00\n",
            "\n",
            "Examples where anchor applies and model predicts hate-speech:\n",
            "\n",
            "UNK ass UNK UNK up UNK machine\n",
            "UNK ass hoe UNK UNK UNK UNK\n",
            "fat ass UNK UNK UNK UNK UNK\n",
            "fat ass hoe UNK up UNK machine\n",
            "UNK ass UNK holding up the UNK\n",
            "UNK ass hoe UNK up UNK UNK\n",
            "UNK ass hoe UNK up the UNK\n",
            "UNK ass UNK UNK UNK UNK machine\n",
            "UNK ass hoe holding UNK the machine\n",
            "fat ass UNK UNK UNK the UNK\n",
            "\n",
            "Examples where anchor applies and model predicts neutral:\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fxZfe94qV4TT"
      },
      "source": [
        "## Using BERT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UkQZ29XPV4TW",
        "outputId": "9435b8d0-a7fd-4433-f263-25c578d6acda"
      },
      "source": [
        "explainer = anchor_text.AnchorText(nlp, ['hate-speech', 'neutral'], use_unk_distribution=False)\n",
        "\n",
        "np.random.seed(1)\n",
        "text = 'fat ass hoe holding up the machine'\n",
        "pred = explainer.class_names[predict_lr([text])[0]]\n",
        "alternative =  explainer.class_names[1 - predict_lr([text])[0]]\n",
        "b = time.time()\n",
        "exp = explainer.explain_instance(text, predict_lr, threshold=0.95, verbose=False)\n",
        "print('Time: %s' % (time.time() - b))\n",
        "\n",
        "print('Text: %s' % text)\n",
        "print('Prediction: %s' % pred)\n",
        "print()\n",
        "print('Anchor: %s' % (' AND '.join(exp.names())))\n",
        "print('Precision: %.2f' % exp.precision())\n",
        "print()\n",
        "print('Examples where anchor applies and model predicts %s:' % pred)\n",
        "print()\n",
        "print('\\n'.join([x[0] for x in exp.examples(only_same_prediction=True)]))\n",
        "print()\n",
        "print('Examples where anchor applies and model predicts %s:' % alternative)\n",
        "print()\n",
        "print('\\n'.join([x[0] for x in exp.examples(only_different_prediction=True)]))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time: 58.357847452163696\n",
            "Text: fat ass hoe holding up the machine\n",
            "Prediction: hate-speech\n",
            "\n",
            "Anchor: ass\n",
            "Precision: 1.00\n",
            "\n",
            "Examples where anchor applies and model predicts hate-speech:\n",
            "\n",
            "[ ass ##ame verb ##urg ##u ##rg\n",
            "thou ass ##ail him under the minute\n",
            "# ass ##am ##pa $ # #\n",
            "con ass ##ion # # # #\n",
            "federal ass ##yrian ##20 # lo ##ndon\n",
            "On ass ##oc ##12 — the funk\n",
            "further ass ##im ##where is the species\n",
            "1 ass ##unta ##pped up info mixtape\n",
            "\\ ass $ t ##w ##ool <\n",
            "< ass / > d \\ text\n",
            "\n",
            "Examples where anchor applies and model predicts neutral:\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pRHn0mZ04X2e"
      },
      "source": [
        "# Polarity"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fUupvE7z7lqK",
        "outputId": "5276abac-b50f-491f-af4a-e796e8eec1bd"
      },
      "source": [
        "dataset_name = 'polarity'\n",
        "data, labels = load_dataset(dataset_name)\n",
        "train, test, train_labels, test_labels = sklearn.model_selection.train_test_split(data, labels, test_size=0.25, random_state=42)\n",
        "train_labels = np.array(train_labels)\n",
        "test_labels = np.array(test_labels)\n",
        "\n",
        "vectorizer = TfidfVectorizer()\n",
        "vectorizer.fit(train)\n",
        "train_vectors = vectorizer.transform(train)\n",
        "test_vectors = vectorizer.transform(test)\n",
        "\n",
        "c = sklearn.ensemble.RandomForestClassifier()\n",
        "c.fit(train_vectors, train_labels)\n",
        "\n",
        "preds = c.predict(test_vectors)\n",
        "\n",
        "print(classification_report(test_labels, preds))\n",
        "print(\"The accuracy score is {:.2%}\".format(accuracy_score(test_labels, preds)))\n",
        "\n",
        "def predict_lr(texts):\n",
        "    return c.predict(vectorizer.transform(texts))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.65      0.71      0.68       339\n",
            "           1       0.67      0.61      0.64       328\n",
            "\n",
            "    accuracy                           0.66       667\n",
            "   macro avg       0.66      0.66      0.66       667\n",
            "weighted avg       0.66      0.66      0.66       667\n",
            "\n",
            "The accuracy score is 65.97%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YXEaBQ2U7x3S"
      },
      "source": [
        "## Without using BERT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lty84nOe72wB",
        "outputId": "17a32bb0-c583-471b-a9b3-205d0dec42ac"
      },
      "source": [
        "explainer = anchor_text.AnchorText(nlp, ['negative', 'positive'], use_unk_distribution=True)\n",
        "\n",
        "np.random.seed(1)\n",
        "text = 'you can practically hear george orwell turning over'\n",
        "pred = explainer.class_names[predict_lr([text])[0]]\n",
        "alternative =  explainer.class_names[1 - predict_lr([text])[0]]\n",
        "exp = explainer.explain_instance(text, predict_lr, threshold=0.95)\n",
        "\n",
        "print('Text: %s' % text)\n",
        "print('Prediction: %s' % pred)\n",
        "print()\n",
        "print('Anchor: %s' % (' AND '.join(exp.names())))\n",
        "print('Precision: %.2f' % exp.precision())\n",
        "print()\n",
        "print('Examples where anchor applies and model predicts %s:' % pred)\n",
        "print()\n",
        "print('\\n'.join([x[0] for x in exp.examples(only_same_prediction=True)]))\n",
        "print()\n",
        "print('Examples where anchor applies and model predicts %s:' % alternative)\n",
        "print()\n",
        "print('\\n'.join([x[0] for x in exp.examples(partial_index=0, only_different_prediction=True)]))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text: you can practically hear george orwell turning over\n",
            "Prediction: negative\n",
            "\n",
            "Anchor: over\n",
            "Precision: 1.00\n",
            "\n",
            "Examples where anchor applies and model predicts negative:\n",
            "\n",
            "you can UNK UNK george orwell turning over\n",
            "you can practically UNK george orwell turning over\n",
            "you can practically UNK UNK orwell UNK over\n",
            "you UNK practically UNK george orwell UNK over\n",
            "UNK UNK practically UNK george orwell turning over\n",
            "UNK can UNK hear george UNK UNK over\n",
            "you UNK UNK hear george orwell UNK over\n",
            "UNK can practically hear UNK UNK turning over\n",
            "UNK can practically UNK UNK UNK turning over\n",
            "you UNK UNK UNK UNK orwell turning over\n",
            "\n",
            "Examples where anchor applies and model predicts positive:\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y-WoEqB079BW"
      },
      "source": [
        "## Using BERT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NIazldh87_WN",
        "outputId": "ba4517f5-07b4-4cd6-9a25-df27b61845fd"
      },
      "source": [
        "explainer = anchor_text.AnchorText(nlp, ['negative', 'positive'], use_unk_distribution=False)\n",
        "\n",
        "np.random.seed(1)\n",
        "text = 'you can practically hear george orwell turning over'\n",
        "pred = explainer.class_names[predict_lr([text])[0]]\n",
        "alternative =  explainer.class_names[1 - predict_lr([text])[0]]\n",
        "b = time.time()\n",
        "exp = explainer.explain_instance(text, predict_lr, threshold=0.95, verbose=False)\n",
        "print('Time: %s' % (time.time() - b))\n",
        "\n",
        "print('Text: %s' % text)\n",
        "print('Prediction: %s' % pred)\n",
        "print()\n",
        "print('Anchor: %s' % (' AND '.join(exp.names())))\n",
        "print('Precision: %.2f' % exp.precision())\n",
        "print()\n",
        "print('Examples where anchor applies and model predicts %s:' % pred)\n",
        "print()\n",
        "print('\\n'.join([x[0] for x in exp.examples(only_same_prediction=True)]))\n",
        "print()\n",
        "print('Examples where anchor applies and model predicts %s:' % alternative)\n",
        "print()\n",
        "print('\\n'.join([x[0] for x in exp.examples(only_different_prediction=True)]))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time: 128.07074093818665\n",
            "Text: you can practically hear george orwell turning over\n",
            "Prediction: negative\n",
            "\n",
            "Anchor: hear\n",
            "Precision: 1.00\n",
            "\n",
            "Examples where anchor applies and model predicts negative:\n",
            "\n",
            "ve - ve hear pro ##met ##her !\n",
            "i can barely hear any s ##hrill ##ia\n",
            "hence can also hear the cry ##k ·\n",
            "does thy foe hear thy foe cry ?\n",
            "we can hardly hear full disco disco ##graphy\n",
            "you can now hear this sweet dragon roar\n",
            "you can always hear voice commands here !\n",
            "com ##place @ hear @ @ seat .\n",
            ": unless we hear : w ##ows ##here\n",
            "< where you hear < poem > ॥\n",
            "\n",
            "Examples where anchor applies and model predicts positive:\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X222O_wvlDk6"
      },
      "source": [
        "# Youtube"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aksrwWPklKkR",
        "outputId": "66e4e99b-56f9-4ef1-807a-276daae30b73"
      },
      "source": [
        "dataset_name = 'youtube'\n",
        "data, labels = YOUTUBE_get_text_data()\n",
        "train, test, train_labels, test_labels = sklearn.model_selection.train_test_split(data, labels, test_size=0.25, random_state=42)\n",
        "train_labels = np.array(train_labels)\n",
        "test_labels = np.array(test_labels)\n",
        "\n",
        "vectorizer = TfidfVectorizer()\n",
        "vectorizer.fit(train)\n",
        "train_vectors = vectorizer.transform(train)\n",
        "test_vectors = vectorizer.transform(test)\n",
        "\n",
        "c = sklearn.ensemble.RandomForestClassifier()\n",
        "c.fit(train_vectors, train_labels)\n",
        "\n",
        "preds = c.predict(test_vectors)\n",
        "\n",
        "print(classification_report(test_labels, preds))\n",
        "print(\"The accuracy score is {:.2%}\".format(accuracy_score(test_labels, preds)))\n",
        "\n",
        "def predict_lr(texts):\n",
        "    return c.predict(vectorizer.transform(texts))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.98      0.92        55\n",
            "           1       0.97      0.80      0.88        45\n",
            "\n",
            "    accuracy                           0.90       100\n",
            "   macro avg       0.92      0.89      0.90       100\n",
            "weighted avg       0.91      0.90      0.90       100\n",
            "\n",
            "The accuracy score is 90.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1wFS1NiCnf9_"
      },
      "source": [
        "## Without using BERT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H46v6JennmUD",
        "outputId": "eb2a1171-69f4-4495-a5e5-a70fe35e2002"
      },
      "source": [
        "explainer = anchor_text.AnchorText(nlp, ['no spam', 'spam'], use_unk_distribution=True)\n",
        "\n",
        "np.random.seed(1)\n",
        "text = 'check out this video on youtube'\n",
        "pred = explainer.class_names[predict_lr([text])[0]]\n",
        "alternative =  explainer.class_names[1 - predict_lr([text])[0]]\n",
        "exp = explainer.explain_instance(text, predict_lr, threshold=0.95)\n",
        "\n",
        "print('Text: %s' % text)\n",
        "print('Prediction: %s' % pred)\n",
        "print()\n",
        "print('Anchor: %s' % (' AND '.join(exp.names())))\n",
        "print('Precision: %.2f' % exp.precision())\n",
        "print()\n",
        "print('Examples where anchor applies and model predicts %s:' % pred)\n",
        "print()\n",
        "print('\\n'.join([x[0] for x in exp.examples(only_same_prediction=True)]))\n",
        "print()\n",
        "print('Examples where anchor applies and model predicts %s:' % alternative)\n",
        "print()\n",
        "print('\\n'.join([x[0] for x in exp.examples(partial_index=0, only_different_prediction=True)]))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text: check out this video on youtube\n",
            "Prediction: spam\n",
            "\n",
            "Anchor: on\n",
            "Precision: 1.00\n",
            "\n",
            "Examples where anchor applies and model predicts spam:\n",
            "\n",
            "check out UNK UNK on UNK\n",
            "check out this UNK on youtube\n",
            "UNK UNK this video on UNK\n",
            "check out this UNK on UNK\n",
            "UNK out this UNK on youtube\n",
            "UNK UNK UNK UNK on UNK\n",
            "UNK out UNK video on youtube\n",
            "check out this UNK on UNK\n",
            "UNK UNK this video on UNK\n",
            "UNK UNK UNK UNK on UNK\n",
            "\n",
            "Examples where anchor applies and model predicts no spam:\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a_v9qbbNnoqR"
      },
      "source": [
        "## Using BERT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cTkZNNnLnrRU",
        "outputId": "4ce922e1-7733-47ff-c4e6-8663bec19f16"
      },
      "source": [
        "explainer = anchor_text.AnchorText(nlp, ['no spam', 'spam'], use_unk_distribution=False)\n",
        "\n",
        "np.random.seed(1)\n",
        "text = 'check out this video on youtube'\n",
        "pred = explainer.class_names[predict_lr([text])[0]]\n",
        "alternative =  explainer.class_names[1 - predict_lr([text])[0]]\n",
        "b = time.time()\n",
        "exp = explainer.explain_instance(text, predict_lr, threshold=0.95, verbose=False)\n",
        "print('Time: %s' % (time.time() - b))\n",
        "\n",
        "print('Text: %s' % text)\n",
        "print('Prediction: %s' % pred)\n",
        "print()\n",
        "print('Anchor: %s' % (' AND '.join(exp.names())))\n",
        "print('Precision: %.2f' % exp.precision())\n",
        "print()\n",
        "print('Examples where anchor applies and model predicts %s:' % pred)\n",
        "print()\n",
        "print('\\n'.join([x[0] for x in exp.examples(only_same_prediction=True)]))\n",
        "print()\n",
        "print('Examples where anchor applies and model predicts %s:' % alternative)\n",
        "print()\n",
        "print('\\n'.join([x[0] for x in exp.examples(only_different_prediction=True)]))"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time: 66.74689674377441\n",
            "Text: check out this video on youtube\n",
            "Prediction: spam\n",
            "\n",
            "Anchor: on\n",
            "Precision: 0.97\n",
            "\n",
            "Examples where anchor applies and model predicts spam:\n",
            "\n",
            "click button \" click on \"\n",
            "here you gotta get on it\n",
            "let build this load on :\n",
            "how going to click on ?\n",
            "check all this data on this\n",
            "( out sun ##day on )\n",
            "only 16 wrestlers got on retirement\n",
            "check ##out ##ping # on !\n",
            "< i > impact on conservation\n",
            "put out her fork on chocolate\n",
            "\n",
            "Examples where anchor applies and model predicts no spam:\n",
            "\n",
            "Who pass this reference on induction\n",
            "the big store went on dark\n",
            "For ##cing this information on :\n",
            "credits from this video on :\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cWyOSsLtiSEU"
      },
      "source": [
        "# Liar"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cWvWeKKNiYQ1",
        "outputId": "44d1f74d-3ffe-43ec-de63-cc036b38821f"
      },
      "source": [
        "dataset_name = 'liar'\n",
        "data, labels = load_dataset(dataset_name)\n",
        "train, test, train_labels, test_labels = sklearn.model_selection.train_test_split(data, labels, test_size=0.25, random_state=42)\n",
        "train_labels = np.array(train_labels)\n",
        "test_labels = np.array(test_labels)\n",
        "\n",
        "vectorizer = TfidfVectorizer()\n",
        "vectorizer.fit(train)\n",
        "train_vectors = vectorizer.transform(train)\n",
        "test_vectors = vectorizer.transform(test)\n",
        "\n",
        "c = sklearn.ensemble.RandomForestClassifier()\n",
        "c.fit(train_vectors, train_labels)\n",
        "\n",
        "preds = c.predict(test_vectors)\n",
        "\n",
        "print(classification_report(test_labels, preds))\n",
        "print(\"The accuracy score is {:.2%}\".format(accuracy_score(test_labels, preds)))\n",
        "\n",
        "def predict_lr(texts):\n",
        "    return c.predict(vectorizer.transform(texts))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.62      0.34      0.44       375\n",
            "           1       0.58      0.82      0.68       425\n",
            "\n",
            "    accuracy                           0.59       800\n",
            "   macro avg       0.60      0.58      0.56       800\n",
            "weighted avg       0.60      0.59      0.57       800\n",
            "\n",
            "The accuracy score is 59.25%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dNcKqiFwiurO"
      },
      "source": [
        "## Without using BERT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sCbvOKecilm2",
        "outputId": "43cb6c35-a83c-482c-ee6c-e193c6fb47db"
      },
      "source": [
        "explainer = anchor_text.AnchorText(nlp, ['fake news', 'real news'], use_unk_distribution=True)\n",
        "\n",
        "np.random.seed(1)\n",
        "text = 'why would our president close the embassy to the vatican hopefully it is not retribution for catholic organizations opposing obamacare'\n",
        "pred = explainer.class_names[predict_lr([text])[0]]\n",
        "alternative =  explainer.class_names[1 - predict_lr([text])[0]]\n",
        "exp = explainer.explain_instance(text, predict_lr, threshold=0.95)\n",
        "\n",
        "print('Text: %s' % text)\n",
        "print('Prediction: %s' % pred)\n",
        "print()\n",
        "print('Anchor: %s' % (' AND '.join(exp.names())))\n",
        "print('Precision: %.2f' % exp.precision())\n",
        "print()\n",
        "print('Examples where anchor applies and model predicts %s:' % pred)\n",
        "print()\n",
        "print('\\n'.join([x[0] for x in exp.examples(only_same_prediction=True)]))\n",
        "print()\n",
        "print('Examples where anchor applies and model predicts %s:' % alternative)\n",
        "print()\n",
        "print('\\n'.join([x[0] for x in exp.examples(partial_index=0, only_different_prediction=True)]))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text: why would our president close the embassy to the vatican hopefully it is not retribution for catholic organizations opposing obamacare\n",
            "Prediction: fake news\n",
            "\n",
            "Anchor: president\n",
            "Precision: 1.00\n",
            "\n",
            "Examples where anchor applies and model predicts fake news:\n",
            "\n",
            "why UNK UNK president close the embassy to the vatican hopefully UNK is not retribution for UNK organizations UNK obamacare\n",
            "UNK would our president UNK the UNK UNK the vatican hopefully it UNK not retribution for catholic UNK opposing UNK\n",
            "UNK UNK our president close the embassy UNK UNK vatican hopefully it UNK UNK UNK UNK catholic UNK UNK obamacare\n",
            "why would our president close the embassy to UNK vatican hopefully it UNK UNK retribution for UNK UNK opposing obamacare\n",
            "why would our president UNK UNK UNK to UNK vatican UNK it UNK not retribution UNK UNK UNK opposing obamacare\n",
            "why would UNK president UNK UNK embassy UNK the vatican UNK it is not UNK UNK UNK organizations UNK UNK\n",
            "UNK would our president close UNK embassy UNK the vatican UNK UNK UNK not retribution UNK catholic UNK UNK obamacare\n",
            "why would UNK president UNK the UNK UNK the UNK UNK UNK is not UNK for UNK UNK UNK UNK\n",
            "UNK would UNK president UNK UNK UNK to the vatican hopefully UNK is not retribution for catholic UNK opposing UNK\n",
            "UNK would UNK president UNK UNK embassy UNK the vatican hopefully UNK is UNK UNK UNK catholic UNK opposing obamacare\n",
            "\n",
            "Examples where anchor applies and model predicts real news:\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JilLtyu8iuLO"
      },
      "source": [
        "## Using BERT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FTHG_21gjEfr",
        "outputId": "2b70c7e0-4ed1-4308-e24a-499bea138456"
      },
      "source": [
        "explainer = anchor_text.AnchorText(nlp, ['fake news', 'real news'], use_unk_distribution=False)\n",
        "\n",
        "np.random.seed(1)\n",
        "text = 'why would our president close the embassy to the vatican hopefully it is not retribution for catholic organizations opposing obamacare'\n",
        "pred = explainer.class_names[predict_lr([text])[0]]\n",
        "alternative =  explainer.class_names[1 - predict_lr([text])[0]]\n",
        "b = time.time()\n",
        "exp = explainer.explain_instance(text, predict_lr, threshold=0.95, verbose=False)\n",
        "print('Time: %s' % (time.time() - b))\n",
        "\n",
        "print('Text: %s' % text)\n",
        "print('Prediction: %s' % pred)\n",
        "print()\n",
        "print('Anchor: %s' % (' AND '.join(exp.names())))\n",
        "print('Precision: %.2f' % exp.precision())\n",
        "print()\n",
        "print('Examples where anchor applies and model predicts %s:' % pred)\n",
        "print()\n",
        "print('\\n'.join([x[0] for x in exp.examples(only_same_prediction=True)]))\n",
        "print()\n",
        "print('Examples where anchor applies and model predicts %s:' % alternative)\n",
        "print()\n",
        "print('\\n'.join([x[0] for x in exp.examples(only_different_prediction=True)]))"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time: 20182.012706518173\n",
            "Text: why would our president close the embassy to the vatican hopefully it is not retribution for catholic organizations opposing obamacare\n",
            "Prediction: fake news\n",
            "\n",
            "Anchor: president AND obamacare AND why AND is AND retribution\n",
            "Precision: 0.97\n",
            "\n",
            "Examples where anchor applies and model predicts fake news:\n",
            "\n",
            "why us vice president ni ##gel ##ato asks the government allegedly responsible is seeking retributi\n",
            "why - vice president ta ##urus ##ea # # # # # is seeking retribution for su ##icidal # obamacare\n",
            "why one assigned president close investigative duty to seek un ##safe living is unlawful retributio\n",
            "why suicide include president na ##bu ##10 # # # # # is ##o retribution terrorist person is made ob\n",
            "why president vice president ng ##azi ##ma ##fia # # # # is seeking retribution for co ##lum ##bi o\n",
            "why critics believe president ta ##my ##cap # # # # trust is my retribution ? nominee grand ##i oba\n",
            "why ##rin ##c president # # # # # # # this is a retribution for some missing people obamacare\n",
            "why r ##pf president un ##ins ##tated su ##pp ##tl # # is ##dn retribution # # # # obamacare\n",
            "why on former president bar ##ack : president ray ##mond ! who is getting retribution worldwide # #\n",
            "why den ##ib president lo ##ren ##weet # # # # # is seeking retribution # # # # obamacare\n",
            "\n",
            "Examples where anchor applies and model predicts real news:\n",
            "\n",
            "why ? Acting president na ##than ##ue # # # if whatever is official retribution w ##ichi ##ma ##kot\n",
            "why sugar vice president – ji ##mmy ##q ##ud ##40 # 40 is in retribution for president bow ##en oba\n",
            "why election for president hi ##rom { ~ ~ | { | is in retribution } < author : obamacare\n",
            "why governors of president na ##than ##ema # # # # # is the retribution for executive president pre\n",
            "why ##bes ##UR president chapter 112 ##1 # # # # # is ##ap retribution claims criminal misconduct i\n",
            "why president vice president or president wa ##lter ##du ##nk ##re ##tribution is used retribution \n",
            "why the incoming president probably was unwilling to ban an abortion ceremony is possible retributi\n",
            "why ##fi ##delity president # # # # # # # # is in retribution for catholic journalist mark obamacar\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MwdC26eQjhWX"
      },
      "source": [
        "# Question"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EgJCBUucjmNU",
        "outputId": "a9d1422b-81be-44fe-cfd1-ee4fa9c4c1dc"
      },
      "source": [
        "dataset_name = 'question'\n",
        "data, labels = load_dataset(dataset_name)\n",
        "train, test, train_labels, test_labels = sklearn.model_selection.train_test_split(data, labels, test_size=0.25, random_state=42)\n",
        "train_labels = np.array(train_labels)\n",
        "test_labels = np.array(test_labels)\n",
        "\n",
        "vectorizer = TfidfVectorizer()\n",
        "vectorizer.fit(train)\n",
        "train_vectors = vectorizer.transform(train)\n",
        "test_vectors = vectorizer.transform(test)\n",
        "\n",
        "c = sklearn.ensemble.RandomForestClassifier()\n",
        "c.fit(train_vectors, train_labels)\n",
        "\n",
        "preds = c.predict(test_vectors)\n",
        "\n",
        "print(classification_report(test_labels, preds))\n",
        "print(\"The accuracy score is {:.2%}\".format(accuracy_score(test_labels, preds)))\n",
        "\n",
        "def predict_lr(texts):\n",
        "    return c.predict(vectorizer.transform(texts))"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "b'Skipping line 205: expected 2 fields, saw 3\\nSkipping line 258: expected 2 fields, saw 3\\nSkipping line 287: expected 2 fields, saw 3\\nSkipping line 298: expected 2 fields, saw 4\\nSkipping line 371: expected 2 fields, saw 3\\nSkipping line 373: expected 2 fields, saw 3\\nSkipping line 418: expected 2 fields, saw 3\\nSkipping line 476: expected 2 fields, saw 3\\nSkipping line 526: expected 2 fields, saw 3\\nSkipping line 590: expected 2 fields, saw 3\\nSkipping line 594: expected 2 fields, saw 3\\nSkipping line 695: expected 2 fields, saw 3\\nSkipping line 793: expected 2 fields, saw 3\\nSkipping line 861: expected 2 fields, saw 3\\nSkipping line 877: expected 2 fields, saw 3\\nSkipping line 930: expected 2 fields, saw 3\\nSkipping line 1003: expected 2 fields, saw 3\\nSkipping line 1113: expected 2 fields, saw 3\\nSkipping line 1306: expected 2 fields, saw 3\\nSkipping line 1406: expected 2 fields, saw 3\\nSkipping line 1411: expected 2 fields, saw 3\\nSkipping line 1700: expected 2 fields, saw 3\\nSkipping line 1784: expected 2 fields, saw 3\\nSkipping line 1798: expected 2 fields, saw 3\\nSkipping line 1910: expected 2 fields, saw 3\\nSkipping line 2021: expected 2 fields, saw 3\\nSkipping line 2039: expected 2 fields, saw 3\\nSkipping line 2096: expected 2 fields, saw 3\\nSkipping line 2311: expected 2 fields, saw 3\\nSkipping line 2346: expected 2 fields, saw 3\\nSkipping line 2422: expected 2 fields, saw 3\\nSkipping line 2469: expected 2 fields, saw 3\\nSkipping line 2499: expected 2 fields, saw 3\\nSkipping line 2527: expected 2 fields, saw 3\\nSkipping line 2562: expected 2 fields, saw 3\\nSkipping line 2563: expected 2 fields, saw 3\\nSkipping line 2564: expected 2 fields, saw 3\\nSkipping line 2707: expected 2 fields, saw 3\\nSkipping line 2778: expected 2 fields, saw 3\\nSkipping line 2797: expected 2 fields, saw 3\\nSkipping line 2857: expected 2 fields, saw 3\\nSkipping line 3153: expected 2 fields, saw 3\\nSkipping line 3174: expected 2 fields, saw 3\\nSkipping line 3676: expected 2 fields, saw 3\\nSkipping line 3781: expected 2 fields, saw 3\\nSkipping line 3813: expected 2 fields, saw 3\\nSkipping line 3837: expected 2 fields, saw 3\\nSkipping line 3852: expected 2 fields, saw 3\\nSkipping line 3858: expected 2 fields, saw 3\\nSkipping line 3868: expected 2 fields, saw 3\\nSkipping line 4044: expected 2 fields, saw 3\\nSkipping line 4146: expected 2 fields, saw 3\\nSkipping line 4201: expected 2 fields, saw 3\\nSkipping line 4516: expected 2 fields, saw 3\\nSkipping line 4818: expected 2 fields, saw 3\\nSkipping line 4938: expected 2 fields, saw 3\\nSkipping line 5073: expected 2 fields, saw 3\\nSkipping line 5213: expected 2 fields, saw 3\\nSkipping line 5307: expected 2 fields, saw 3\\nSkipping line 5356: expected 2 fields, saw 3\\nSkipping line 5381: expected 2 fields, saw 3\\n'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.24      0.37        83\n",
            "           1       0.82      0.98      0.89       286\n",
            "\n",
            "    accuracy                           0.82       369\n",
            "   macro avg       0.81      0.61      0.63       369\n",
            "weighted avg       0.81      0.82      0.77       369\n",
            "\n",
            "The accuracy score is 81.57%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xHALAM23jrsY"
      },
      "source": [
        "## Without using BERT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a4AWlUHgjxgu",
        "outputId": "91f1d2e0-f3ef-460f-c9ba-8e29b5c788ad"
      },
      "source": [
        "explainer = anchor_text.AnchorText(nlp, ['entity', 'all other classes'], use_unk_distribution=True)\n",
        "\n",
        "np.random.seed(1)\n",
        "text = 'what is money made of'\n",
        "pred = explainer.class_names[predict_lr([text])[0]]\n",
        "alternative =  explainer.class_names[1 - predict_lr([text])[0]]\n",
        "exp = explainer.explain_instance(text, predict_lr, threshold=0.95)\n",
        "\n",
        "print('Text: %s' % text)\n",
        "print('Prediction: %s' % pred)\n",
        "print()\n",
        "print('Anchor: %s' % (' AND '.join(exp.names())))\n",
        "print('Precision: %.2f' % exp.precision())\n",
        "print()\n",
        "print('Examples where anchor applies and model predicts %s:' % pred)\n",
        "print()\n",
        "print('\\n'.join([x[0] for x in exp.examples(only_same_prediction=True)]))\n",
        "print()\n",
        "print('Examples where anchor applies and model predicts %s:' % alternative)\n",
        "print()\n",
        "print('\\n'.join([x[0] for x in exp.examples(partial_index=0, only_different_prediction=True)]))"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text: what is money made of\n",
            "Prediction: entity\n",
            "\n",
            "Anchor: of AND made AND what\n",
            "Precision: 1.00\n",
            "\n",
            "Examples where anchor applies and model predicts entity:\n",
            "\n",
            "what UNK money made of\n",
            "what UNK UNK made of\n",
            "what is UNK made of\n",
            "what is money made of\n",
            "what is money made of\n",
            "what UNK money made of\n",
            "what is UNK made of\n",
            "what UNK money made of\n",
            "what UNK UNK made of\n",
            "what UNK money made of\n",
            "\n",
            "Examples where anchor applies and model predicts all other classes:\n",
            "\n",
            "what UNK UNK UNK of\n",
            "what UNK UNK UNK of\n",
            "what is UNK UNK of\n",
            "what UNK UNK UNK of\n",
            "UNK UNK money UNK of\n",
            "UNK is money UNK of\n",
            "what UNK UNK UNK of\n",
            "what is UNK UNK of\n",
            "UNK is money UNK of\n",
            "what is money UNK of\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YeGXuiEOjr0U"
      },
      "source": [
        "## Using BERT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "60kmwUiej0FZ",
        "outputId": "3715b81f-1de4-4f28-835b-303ff55cdd9d"
      },
      "source": [
        "explainer = anchor_text.AnchorText(nlp, ['entity', 'all other classes'], use_unk_distribution=False)\n",
        "\n",
        "np.random.seed(1)\n",
        "text = 'what is money made of'\n",
        "pred = explainer.class_names[predict_lr([text])[0]]\n",
        "alternative =  explainer.class_names[1 - predict_lr([text])[0]]\n",
        "b = time.time()\n",
        "exp = explainer.explain_instance(text, predict_lr, threshold=0.95, verbose=False)\n",
        "print('Time: %s' % (time.time() - b))\n",
        "\n",
        "print('Text: %s' % text)\n",
        "print('Prediction: %s' % pred)\n",
        "print()\n",
        "print('Anchor: %s' % (' AND '.join(exp.names())))\n",
        "print('Precision: %.2f' % exp.precision())\n",
        "print()\n",
        "print('Examples where anchor applies and model predicts %s:' % pred)\n",
        "print()\n",
        "print('\\n'.join([x[0] for x in exp.examples(only_same_prediction=True)]))\n",
        "print()\n",
        "print('Examples where anchor applies and model predicts %s:' % alternative)\n",
        "print()\n",
        "print('\\n'.join([x[0] for x in exp.examples(only_different_prediction=True)]))"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time: 203.67003774642944\n",
            "Text: what is money made of\n",
            "Prediction: entity\n",
            "\n",
            "Anchor: of AND made AND what\n",
            "Precision: 1.00\n",
            "\n",
            "Examples where anchor applies and model predicts entity:\n",
            "\n",
            "what is currently made of\n",
            "what thy skin made of\n",
            "what does be made of\n",
            "what is usually made of\n",
            "what is she made of\n",
            "what is she made of\n",
            "what has been made of\n",
            "what they were made of\n",
            "what they are made of\n",
            "what is honey made of\n",
            "\n",
            "Examples where anchor applies and model predicts all other classes:\n",
            "\n",
            "\n"
          ]
        }
      ]
    }
  ]
}